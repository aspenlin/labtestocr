{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import imutils \n",
    "import cv2 \n",
    "import os\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "from tesserocr import PyTessBaseAPI, PSM, RIL\n",
    "import sys\n",
    "import re\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShadowRemover():\n",
    "\n",
    "    def __init__(self):\n",
    "        # Default algorithmic parameters\n",
    "        self.stride = 20;                 # Number of pixels to skip when performing local analysis\n",
    "        self.blockSize = self.stride;     # Size of overlapping blocks in local analysis\n",
    "        self.numOfClusters = 4;           # Number of clusters used for local analysis\n",
    "        self.maxIters = 100;              # Maximum number of iterations used as stopping condition for GMM clustering. \n",
    "        self.emEps = 0.1;                # Epsilon threshold used as stopping condition for GMM clustering.\n",
    "        self.diffThres = 30;\n",
    "        self.clearThres = 40;\n",
    "\n",
    "\n",
    "    def GetBlock(self, x, y, dsImage, width, height):\n",
    "        minX = x\n",
    "        maxX = min(width, x + self.blockSize)\n",
    "        minY = y\n",
    "        maxY = min(height, y + self.blockSize)\n",
    "        block = np.array([dsImage[y][minX:maxX] for y in range(minY, maxY)])\n",
    "        return block;\n",
    "\n",
    "    def PutBlock(self, x, y, newImg, newBlock):\n",
    "        for i in range(y, y + len(newBlock)):\n",
    "            newImg[i][x:x+len(newBlock[i - y])] = newBlock[i - y]\n",
    "\n",
    "    def ClusterBlock(self, block):\n",
    "    #     X,Y = make_blobs(cluster_std=0.5,random_state=20,n_samples=1000,centers=5)\n",
    "        # Stratch dataset to get ellipsoid data\n",
    "        emModel = GaussianMixture(n_components=self.numOfClusters, covariance_type= 'diag', max_iter=self.maxIters, tol=self.emEps)\n",
    "        originalShape = (len(block), -1)\n",
    "        block_flat = block.reshape((-1, 1))\n",
    "\n",
    "        if len(block_flat) < self.numOfClusters:\n",
    "            dst = np.zeros_like(block)\n",
    "            cv2.normalize(block, dst, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "            return None, None, dst\n",
    "\n",
    "        samples = block_flat.copy()\n",
    "        samples = np.array(samples)\n",
    "        emModel.fit(samples)\n",
    "        predict_probs = emModel.predict_proba(samples)\n",
    "\n",
    "        means = emModel.means_ \n",
    "        covariances = emModel.covariances_\n",
    "\n",
    "        order = sorted(range(len(means)), key = lambda x : means[x])\n",
    "        means = np.array(sorted(means))\n",
    "        predict_probs = np.array([[p[o] for o in order] for p in predict_probs])\n",
    "\n",
    "        if (abs(means[0] - means[-1]) < self.clearThres):\n",
    "            predicts = np.ones(len(predict_probs))\n",
    "        else:\n",
    "            lowest = means[0]\n",
    "            highest = means[-1]\n",
    "            values = np.array([int(abs(m - lowest) >= self.diffThres) * 1 * int(abs(m - highest) < self.diffThres) + min(1, 1.1 * (m - lowest) / (highest - lowest)) * int(abs(m - highest) >= self.diffThres and abs(m - lowest) >= self.diffThres) for m in means])\n",
    "            predicts = []\n",
    "            for p in predict_probs:\n",
    "                predicts.append(np.dot(p, values))\n",
    "            predicts = np.array(predicts)\n",
    "\n",
    "        predicts = np.array([predicts * 255])\n",
    "        return means, covariances, predicts.reshape(originalShape)\n",
    "\n",
    "    # main function\n",
    "    def RemoveShadow(self, image):\n",
    "        width = len(image[0])\n",
    "        height = len(image)\n",
    "\n",
    "        newImg = image.copy()\n",
    "        i = 0\n",
    "        while i < height:\n",
    "            j = 0\n",
    "            while j < width:\n",
    "                block = self.GetBlock(j, i, image, width, height)\n",
    "                means, covariances, newBlock = self.ClusterBlock(block)\n",
    "                self.PutBlock(j, i, newImg, newBlock)\n",
    "                \n",
    "                j += self.stride\n",
    "            i += self.stride\n",
    "        return newImg\n",
    "\n",
    "\n",
    "class ImageProcessor():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.shadowRemover = ShadowRemover()\n",
    "\n",
    "    def findMatrices(self, matrix, edge):\n",
    "        matrices = [matrix]\n",
    "        left = [matrix]\n",
    "        right = [matrix]\n",
    "        bot = [matrix]\n",
    "        top = [matrix]\n",
    "        \n",
    "        moveRight = lambda m: np.insert(np.delete(m,0,1), -1, 0, axis=1)\n",
    "        moveLeft = lambda m: np.insert(np.delete(m,-1,1), 0, 0, axis=1)\n",
    "        moveTop = lambda m: np.insert(np.delete(m,-1,0), 0, 0, axis=0)\n",
    "        moveBot = lambda m: np.insert(np.delete(m,0,0), -1, 0, axis=0)\n",
    "\n",
    "        def loop_side(l, f):\n",
    "            for _ in range(len(l)):\n",
    "                m = l.pop(0)\n",
    "                m = f(m)\n",
    "                l.append(m)\n",
    "                matrices.append(m)\n",
    "\n",
    "        for i in range(1, edge + 1):\n",
    "            loop_side(right, moveRight)\n",
    "            loop_side(left, moveLeft)\n",
    "            loop_side(top, moveTop)\n",
    "            loop_side(bot, moveBot)\n",
    "\n",
    "            leftTop = moveTop(left[0])\n",
    "            left.insert(0, leftTop)\n",
    "            top.insert(0, leftTop)\n",
    "            matrices.append(leftTop)\n",
    "            \n",
    "            rightTop = moveTop(right[0])\n",
    "            right.insert(0, rightTop)\n",
    "            top.append(rightTop)\n",
    "            matrices.append(rightTop)\n",
    "            \n",
    "            leftBot = moveBot(left[-1])\n",
    "            left.append(leftBot)\n",
    "            bot.insert(0, leftBot)\n",
    "            matrices.append(leftBot)\n",
    "            \n",
    "            rightBot = moveTop(right[-1])\n",
    "            right.append(rightBot)\n",
    "            top.append(rightBot)\n",
    "            matrices.append(rightBot)\n",
    "\n",
    "        return matrices\n",
    "        \n",
    "    def contrast_img(self, matrix):\n",
    "        \n",
    "        dst = np.zeros_like(matrix)\n",
    "        cv2.normalize(matrix, dst, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "        matrix = dst\n",
    "        \n",
    "        edge = 2\n",
    "        matrices = self.findMatrices(matrix, edge)\n",
    "        \n",
    "        mean_matrix = np.sum(matrices, axis=0) / len(matrices)\n",
    "        demean_matrices = np.array(matrices) - mean_matrix\n",
    "        std_matrix = np.sum(demean_matrices ** 2, axis=0) ** 0.5\n",
    "        mean_std = np.mean(std_matrix)\n",
    "        \n",
    "        judge_matrix_dark = np.where((matrix < mean_matrix) & (std_matrix > 0.8 * mean_std), matrix, 0)\n",
    "        matrix = (matrix - 0.5 * judge_matrix_dark).astype('uint8')\n",
    "        \n",
    "        return matrix\n",
    "\n",
    "    def init_resize(self, img):\n",
    "        while len(img) > 2000 or len(img[0]) > 2000:\n",
    "            img = cv2.resize(img, (int(len(img[0]) / 1.5), int(len(img) / 1.5)))\n",
    "        return img\n",
    "\n",
    "    def denoiseOnce(self, matrix, e):\n",
    "        matrices = self.findMatrices(matrix, e)\n",
    "        count_black = np.zeros_like(matrix).astype('int64')\n",
    "        thres = min(e * 2, len(matrices) // 8)\n",
    "        for m in matrices:\n",
    "            count_black += np.where(m.astype('int64') < 200, 1, 0)\n",
    "\n",
    "        matrix = np.where(count_black > thres, matrix, 255).astype('uint8')\n",
    "        return matrix\n",
    "\n",
    "    def denoise(self, matrix, edge = 2):\n",
    "        for e in range(1, edge + 1):\n",
    "            matrix = self.denoiseOnce(matrix, e)\n",
    "        for e in range(edge - 1, 0, -1):\n",
    "            matrix = self.denoiseOnce(matrix, e)\n",
    "        rt = np.zeros_like(matrix).astype('int64')\n",
    "        while not np.array_equal(rt, matrix):\n",
    "            rt = matrix\n",
    "            matrix = self.denoiseOnce(matrix, 1)\n",
    "        return matrix\n",
    "        \n",
    "\n",
    "    def generateGray(self, img):\n",
    "        img = self.init_resize(img)\n",
    "        matrix = np.array(img) \n",
    "        matrix = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        matrix = cv2.GaussianBlur(matrix, (7, 7), 0.6)\n",
    "        matrix = self.contrast_img(matrix)\n",
    "        print(\"remove shadow\")\n",
    "        matrix = cv2.adaptiveThreshold(matrix, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                     cv2.THRESH_BINARY,\n",
    "                                     101,\n",
    "                                     25)\n",
    "#         matrix = self.shadowRemover.RemoveShadow(matrix)\n",
    "        rt = np.zeros_like(matrix).astype('int64')\n",
    "        edge = min(min(len(matrix), len(matrix[0])) // 100, 3)\n",
    "        print(\"denoise\")\n",
    "        matrix = self.denoise(matrix, edge)\n",
    "\n",
    "        varM = cv2.Laplacian(matrix, cv2.CV_64F)\n",
    "        rt = np.array(matrix).astype('uint8')\n",
    "        print(\"done\")\n",
    "\n",
    "        return rt\n",
    "\n",
    "    def process_image(self, scr_path, dst_path, dpi = 70):\n",
    "        img_ori = cv2.imread(scr_path)\n",
    "        result = self.generateGray(img_ori)\n",
    "        Image.fromarray(result).save(dst_path, dpi=(dpi, dpi))\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=15):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_components = 30\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# SYMBOLS = '()[]{}+-*/<=>^~.%#\\\\↑↓'\n",
    "# NUMBERS = '0123456789'\n",
    "# LETTERS = 'abcdefghigklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "# CHARBASE = '序号英文名称中文名称结果状态单位参考值项目结果参考值单位简称参考范围单位检测方法检验项目测定结果区间提示备注代码缩写代号'\n",
    "\n",
    "# # img_ori = cv2.imread(\"../Jerry.in/bloodtest20.jpeg\")\n",
    "# img_ori = cv2.imread(\"../Jerry.hard.in/c1-1.jpg\")\n",
    "\n",
    "# img = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "# Image.fromarray(img, \"L\").show()\n",
    "# result = ImageProcessor().generateGray(img_ori)\n",
    "# p = Image.fromarray(result, \"L\")\n",
    "# p.show()\n",
    "\n",
    "# def getData(img):\n",
    "#     data = set()\n",
    "#     for j, row in enumerate(np.array(im)):\n",
    "#         for i, col in enumerate(row):\n",
    "#             if col < 90:\n",
    "#                 data.add(i)\n",
    "#     data = [[x] for x in data]\n",
    "#     data = np.array(data)\n",
    "#     return data\n",
    "\n",
    "# # remove space after dot, which is a common error in tesseract result\n",
    "# def remove_space_after_dot(text):\n",
    "#     num = 0\n",
    "#     for i in range(len(text)-1):\n",
    "#         if num+i >= len(text)-1:\n",
    "#             break\n",
    "#         if (text[i] == '.') & (text[1+i] == ' '):\n",
    "#             num += 1\n",
    "#             text = text[:i+1] + text[i+2:]\n",
    "#     return text\n",
    "\n",
    "\n",
    "# # def getData(img):\n",
    "# #     thres = 3\n",
    "# #     data = set()\n",
    "# #     im = np.array(img)\n",
    "# #     for j in range(0, len(im), thres):\n",
    "# #         for i in range(0, len(im[0]), thres):\n",
    "# #             block = im[j:min(len(im), j + thres), i:min(len(im[0]), i + thres)]\n",
    "# #             sumblack = np.sum(block[block<100].astype(int))\n",
    "# #             if sumblack > 0:\n",
    "# #                 data.add(i + thres // 2)\n",
    "# #     data = [[x] for x in data]\n",
    "# #     data = np.array(data)\n",
    "# #     return data\n",
    "\n",
    "# judge = lambda text: re.match(r'.*[-\\d]+\\.$', text)\n",
    "\n",
    "# image = Image.fromarray(result, \"L\")\n",
    "# image_2 = cv2.cvtColor(np.array(image), cv2.COLOR_GRAY2RGB)\n",
    "# with PyTessBaseAPI(lang='chi_sim',psm=6) as api:\n",
    "#     api.SetVariable('tessedit_char_whitelist',''.join(set('<=-～()+-abcdefghijklmnopqrstuvwxyz/\\\n",
    "#                 葡萄糖白细胞计数中性目百变异系标准差网织率总比↑\\\n",
    "#                 ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890.\\\n",
    "#                 %淋巴细胞单核嗜酸粒碱绝对值红蛋血压积平均量\\\n",
    "#                 浓度分布宽小板体性沉大肺炎支原反应' + SYMBOLS + NUMBERS + LETTERS + CHARBASE)))\n",
    "#     api.SetVariable('preserve_interword_spaces','1')\n",
    "#     api.SetImage(Image.fromarray(result, \"L\"))\n",
    "    \n",
    "    \n",
    "#     #1\n",
    "#     t = api.GetHOCRText(0)\n",
    "#     print(t)\n",
    "    \n",
    "#     #2\n",
    "# #     lines = api.GetComponentImages(RIL.TEXTLINE, True) # 查找图像内图像块，并将分割后的图像块返回到boxes迭代器中\n",
    "\n",
    "\n",
    "#     words = api.GetComponentImages(RIL.WORD, True)\n",
    "    \n",
    "    \n",
    "#     for im, box, _, _ in words:\n",
    "#         x, y, w, h = box['x'], box['y'], box['w'], box['h'] \n",
    "        \n",
    "#         #1\n",
    "#         meanx, meany = x + w // 2, y + h // 2\n",
    "#         cv2.rectangle(image_2, (meanx, meany), (meanx + 1, meany + 1), (0, 255, 0), 1)\n",
    "        \n",
    "#         #2\n",
    "# #         cv2.rectangle(image_2, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         #2\n",
    "# #     wordI = 0\n",
    "# #     print('Found {0} textline image components.'.format(len(lines)))\n",
    "# #     print('Found {0} word image components.'.format(len(words)))\n",
    "# #     for i, (im, box, _, _) in enumerate(lines):\n",
    "# #         x, y, w, h = box['x'], box['y'], box['w'], box['h']      \n",
    "        \n",
    "        \n",
    "# #         emModel = GaussianMixture(n_components=n_components, covariance_type= 'diag', max_iter=10000, tol=0.001)\n",
    "# #         x, y, w, h = box['x'], box['y'], box['w'], box['h']\n",
    "        \n",
    "# # #         print(x, y, w, h)\n",
    "        \n",
    "# #         data = getData(img)\n",
    "# # #         print(data)\n",
    "# # #         k, _ = optimalK(data, nrefs=1, maxClusters=8)\n",
    "# # #         emModel = GaussianMixture(n_components=k + 1, covariance_type= 'diag', max_iter=10000, tol=0.001)\n",
    "# #         emModel.fit(data)\n",
    "        \n",
    "        \n",
    "# # #         data = np.array(emModel.means_)\n",
    "# # #         k, _ = optimalK(data, nrefs=1, maxClusters=n_components)\n",
    "# # #         emModel = GaussianMixture(n_components=k + 1, covariance_type= 'diag', max_iter=10000, tol=0.001)\n",
    "# # #         emModel.fit(data)\n",
    "        \n",
    "# #         clusters = [[] for _ in range(len(emModel.means_))]\n",
    "        \n",
    "# #         def map_cluster_builder(means):\n",
    "# #             l = sorted(enumerate(means), key = lambda x:x[1])\n",
    "# #             d = {ix:i for i, (ix, x) in enumerate(l)}\n",
    "# #             def map_cluster(predict):\n",
    "# #                 return d[predict]\n",
    "# #             return map_cluster\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "# #         means = []\n",
    "# #         for x_cluster_l in emModel.means_:\n",
    "# #             x_cluster = x_cluster_l[0]\n",
    "# #             means.append(x_cluster)\n",
    "# # #             cv2.rectangle(image_2, (x + int(x_cluster), y + h // 2), (x + int(x_cluster) + 1, y + h // 2 + 1), (0, 0, 255), 2)\n",
    "# #         map_cluster = map_cluster_builder(means)\n",
    "# #         while wordI < len(words):\n",
    "# #             try:\n",
    "# #                 im_w, box_w, _, _ = words[wordI]\n",
    "# #                 x_w, y_w, w_w, h_w = box_w['x'], box_w['y'], box_w['w'], box_w['h']\n",
    "# # #                 cv2.rectangle(image_2, (x_w, y_w), (x_w + w_w, y_w + h_w), (255, 0, 0), 1)\n",
    "# #                 box_mean = [x_w + w_w // 2, y_w + h_w // 2]\n",
    "# # #                 print(box_mean)\n",
    "# #                 if not(box_mean[0] > x and box_mean[0] < x + w and box_mean[1] > y and box_mean[1] < y + h):\n",
    "# # #                     print(box_mean[0], x, box_mean[1], y)\n",
    "# #                     break\n",
    "# #                 wordI += 1\n",
    "# #                 predict = emModel.predict(np.array([[box_mean[0] - x]]))[0]\n",
    "# #                 clusters[map_cluster(predict)].append([x_w, y_w, w_w + x_w, h_w + y_w])\n",
    "# #             except StopIteration:\n",
    "# #                 break\n",
    "# # #         print([len(x) for x in clusters])\n",
    "# #         display(im)\n",
    "        \n",
    "        \n",
    "# #         word_boxes = []\n",
    "        \n",
    "        \n",
    "# #         for c in clusters:\n",
    "# #             if len(c) > 0:\n",
    "# #                 dim = list(zip(*c))\n",
    "# #                 x_c, y_c, xe_c, ye_c = min(dim[0]), min(dim[1]), max(dim[2]), max(dim[3])\n",
    "# #                 word_boxes.append([x_c, y_c, xe_c, ye_c])\n",
    "\n",
    "# #         final_wb = []\n",
    "# #         final_w_rec = []\n",
    "# #         for i_wb, (x_wb, y_wb, xe_wb, ye_wb) in enumerate(word_boxes):\n",
    "# #             api.SetImage(Image.fromarray(result, \"L\"))\n",
    "# #             api.SetRectangle(x_wb - 5, y_wb - 2, xe_wb + 10 - x_wb, ye_wb + 4 - y_wb)\n",
    "# #             cv2.rectangle(image_2, (x_wb - 5, y_wb - 2), (xe_wb + 5, ye_wb + 2), (255, 0, 0), 1)\n",
    "# #             text = api.GetUTF8Text()\n",
    "# #             text = re.sub(r\"[\\s\\n]\", \"\", text)\n",
    "# #             print(text)\n",
    "            \n",
    "# #             if judge(text) and i_wb < len(word_boxes) - 1:\n",
    "# #                 word_boxes[i_wb + 1] = [x_wb, y_wb, word_boxes[i_wb + 1][2], word_boxes[i_wb + 1][3]]\n",
    "# #             else:\n",
    "# #                 final_wb.append([x_wb, y_wb, xe_wb, ye_wb])\n",
    "# #                 final_w_rec.append(text)\n",
    "# #                 cv2.rectangle(image_2, (x_wb, y_wb), (xe_wb, ye_wb), (0, 255, 0), 2)\n",
    "# #         print(final_w_rec)\n",
    "                \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# Image.fromarray(image_2, \"RGB\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove shadow\n",
      "denoise\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "n_components = 30\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "SYMBOLS = '()[]{}+-*/<=>^~.%#\\\\↑↓'\n",
    "NUMBERS = '0123456789'\n",
    "LETTERS = 'abcdefghigklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "CHARBASE = '序号英文名称中文名称结果状态单位参考值项目结果参考值单位简称参考范围单位检测方法检验项目测定结果区间提示备注代码缩写代号'\n",
    "\n",
    "# img_ori = cv2.imread(\"../Jerry.in/bloodtest20.jpeg\")\n",
    "img_ori = cv2.imread(\"../Jerry.hard.in/c1-1.jpg\")\n",
    "\n",
    "img = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "Image.fromarray(img, \"L\").show()\n",
    "result = ImageProcessor().generateGray(img_ori)\n",
    "p = Image.fromarray(result, \"L\")\n",
    "p.show()\n",
    "\n",
    "def getData(img):\n",
    "    data = set()\n",
    "    for j, row in enumerate(np.array(im)):\n",
    "        for i, col in enumerate(row):\n",
    "            if col < 90:\n",
    "                data.add(i)\n",
    "    data = [[x] for x in data]\n",
    "    data = np.array(data)\n",
    "    return data\n",
    "\n",
    "# remove space after dot, which is a common error in tesseract result\n",
    "def remove_space_after_dot(text):\n",
    "    num = 0\n",
    "    for i in range(len(text)-1):\n",
    "        if num+i >= len(text)-1:\n",
    "            break\n",
    "        if (text[i] == '.') & (text[1+i] == ' '):\n",
    "            num += 1\n",
    "            text = text[:i+1] + text[i+2:]\n",
    "    return text\n",
    "\n",
    "judge = lambda text: re.match(r'.*[-\\d]+\\.$', text)\n",
    "\n",
    "image = Image.fromarray(result, \"L\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_2 = cv2.cvtColor(np.array(image), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "with PyTessBaseAPI(lang='chi_sim',psm=6) as api:\n",
    "    api.SetVariable('tessedit_char_whitelist',''.join(set('<=-～()+-abcdefghijklmnopqrstuvwxyz/\\\n",
    "                葡萄糖白细胞计数中性目百变异系标准差网织率总比↑\\\n",
    "                ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890.\\\n",
    "                %淋巴细胞单核嗜酸粒碱绝对值红蛋血压积平均量\\\n",
    "                浓度分布宽小板体性沉大肺炎支原反应' + SYMBOLS + NUMBERS + LETTERS + CHARBASE)))\n",
    "    api.SetVariable('preserve_interword_spaces','1')\n",
    "    api.SetImage(Image.fromarray(result, \"L\"))\n",
    "    \n",
    "\n",
    "    t = api.GetHOCRText(0)\n",
    "#     print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span:\n",
    "    def __init__(self, className, identity, title, content = None):\n",
    "        self.className = className\n",
    "        self.id = identity\n",
    "        self.box = self.titleParser(title)\n",
    "        self.content = content\n",
    "    \n",
    "    def setContent(self, content):\n",
    "        self.content = content\n",
    "        \n",
    "    def titleParser(self, title):\n",
    "        title_list = title.split()\n",
    "        rt = title_list[1:5]\n",
    "        rt[3] = rt[3][:-1]\n",
    "        return [int(x) for x in rt]\n",
    "    \n",
    "    def isWord(self):\n",
    "        return className == \"ocrx_word\" and type(self.content) == str\n",
    "    \n",
    "    def isLine(self):\n",
    "        return className == \"ocr_line\"\n",
    "    \n",
    "def findIndent(s):\n",
    "    rt = 0\n",
    "    for i in s:\n",
    "        if i != \" \":\n",
    "            return rt\n",
    "        rt += 1\n",
    "    return 0\n",
    "\n",
    "def getHeaderValue(s, index):\n",
    "    key = \"\"\n",
    "    value = \"\"\n",
    "    isKey = True\n",
    "    startedValue = False\n",
    "    for l in s[index:]:\n",
    "        if isKey and l == \"=\":\n",
    "            isKey = False\n",
    "        elif isKey:\n",
    "            key += l\n",
    "        elif l == \"'\" and not startedValue:\n",
    "            startedValue = True\n",
    "        elif l == \"'\" and startedValue:\n",
    "            return value\n",
    "        else:\n",
    "            value += l\n",
    "    return value\n",
    "            \n",
    "\n",
    "def decomposeHeader(s):\n",
    "    classIndex = s.find(\"class=\")\n",
    "    idIndex = s.find(\"id=\")\n",
    "    titleIndex = s.find(\"title=\")\n",
    "    span = Span(getHeaderValue(s, classIndex), getHeaderValue(s, idIndex), getHeaderValue(s, titleIndex))\n",
    "    return span\n",
    "    \n",
    "    \n",
    "def parseSpanWord(s):\n",
    "    s = s.strip()\n",
    "    s = s[:s.find(\"</span>\")]\n",
    "    x_wconf_index = s.find(\"x_wconf\")\n",
    "    wordStartIndex = s.find(\">\", x_wconf_index) + 1\n",
    "    content = s[wordStartIndex:]\n",
    "    header = s[:wordStartIndex]\n",
    "    span = decomposeHeader(header)\n",
    "    span.setContent(content)\n",
    "    return span\n",
    "    \n",
    "def parseSpanLine(s):\n",
    "    indent = findIndent(s)\n",
    "    endPreIndex = s.find(indent * \" \" + \"</span>\")\n",
    "    nextLineIndex = s.find(\"\\n\", endPreIndex)\n",
    "    if nextLineIndex > 0:\n",
    "        endPreIndex = nextLineIndex\n",
    "    else:\n",
    "        endPreIndex = len(s)\n",
    "    restS = s[endPreIndex + 1:]\n",
    "    s = s[:endPreIndex]\n",
    "    s_list = s.split(\"\\n\")\n",
    "    info = s_list.pop(0)\n",
    "    span = decomposeHeader(info)\n",
    "    s_list.pop()\n",
    "    content = []\n",
    "    for s_word in s_list:\n",
    "        content.append(parseSpanWord(s_word))\n",
    "    span.setContent(content)\n",
    "    return span, restS\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def parseHOCR(HOCR_s):\n",
    "    rt = []\n",
    "    startIndex = HOCR_s.find(\"<span\")\n",
    "    startIndex = HOCR_s.rfind(\"\\n\", 0, startIndex) + 1\n",
    "    endIndex = HOCR_s.rfind(\"</span>\") + 7\n",
    "    s = HOCR_s[startIndex:endIndex]\n",
    "    while s.strip() != \"\":\n",
    "        span, s = parseSpanLine(s)\n",
    "        rt.append(span)\n",
    "    return rt\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hocr_t = parseHOCR(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_2 = cv2.cvtColor(np.array(image), cv2.COLOR_GRAY2RGB)\n",
    "for line in hocr_t:\n",
    "    for word in line.content:\n",
    "        box = word.box\n",
    "        cv2.rectangle(image_2, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "Image.fromarray(image_2, \"RGB\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYMBOLS = '()[]{}+-*/<=>^、~.,?!%;:#\\'\\\"\\\\↑↓'\n",
    "# NUMBERS = '0123456789'\n",
    "# LETTERS = 'abcdefghigklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "# CHARBASE = '序号英文名称中文名称结果状态单位参考值项目结果参考值单位简称参考范围单位检测方法检验项目测定结果区间提示备注代码缩写代号'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with PyTessBaseAPI(lang='chi_sim',psm=6) as api:\n",
    "#     api.SetVariable('tessedit_char_whitelist',''.join(set('<=-～()+-abcdefghijklmnopqrstuvwxyz/\\\n",
    "#                 葡萄糖白细胞计数中性目百变异系标准差网织率总比↑\\\n",
    "#                 ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890.\\\n",
    "#                 %淋巴细胞单核嗜酸粒碱绝对值红蛋血压积平均量\\\n",
    "#                 浓度分布宽小板体性沉大肺炎支原反应' + SYMBOLS + NUMBERS + LETTERS + CHARBASE)))\n",
    "#     api.SetVariable('preserve_interword_spaces','1')\n",
    "#     api.SetImage(Image.fromarray(result, \"L\"))\n",
    "#     text = api.GetUTF8Text()\n",
    "#     boxes = api.GetComponentImages(RIL.WORD, True) # 查找图像内图像块，并将分割后的图像块返回到boxes迭代器中\n",
    "#     print('Found {0} textline image components.'.format(len(boxes)))\n",
    "# #     for i, (im, box, _, _) in enumerate(boxes):\n",
    "# #         x, y, w, h = box['x'], box['y'], box['w'], box['h']\n",
    "# #         cv2.rectangle(image_2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imutils \n",
    "# # load the image and compute the ratio of the old height\n",
    "# # to the new height, clone it, and resize it\n",
    "# image = cv2.imread(\"../Jerry.in/bloodtest20.jpeg\")\n",
    "# ratio = image.shape[0] / 500.0\n",
    "# orig = image.copy()\n",
    "# image = imutils.resize(image, height = 500)\n",
    " \n",
    "# # convert the image to grayscale, blur it, and find edges\n",
    "# # in the image\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "# # show the original image and the edge detected image\n",
    "# print(\"STEP 1: Edge Detection\")\n",
    "# Image.fromarray(image, \"RGB\").show()\n",
    "# Image.fromarray(edged, \"L\").show()\n",
    "\n",
    "\n",
    "# # find the contours in the edged image, keeping only the\n",
    "# # largest ones, and initialize the screen contour\n",
    "# cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = imutils.grab_contours(cnts)\n",
    "# cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# screenCnt = []\n",
    "\n",
    "# # loop over the contours\n",
    "# for c in cnts:\n",
    "#     # approximate the contour\n",
    "#     peri = cv2.arcLength(c, True)\n",
    "#     approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    " \n",
    "#     # if our approximated contour has four points, then we\n",
    "#     # can assume that we have found our screen\n",
    "#     if len(approx) == 4:\n",
    "#         screenCnt = approx\n",
    "#         break\n",
    "# if len(screenCnt) != 0:\n",
    "#     # show the contour (outline) of the piece of paper\n",
    "#     print(\"STEP 2: Find contours of paper\")\n",
    "#     cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "#     cv2.imshow(\"Outline\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tesserocr import PyTessBaseAPI, PSM, RIL\n",
    "# import imutils\n",
    " \n",
    "# with PyTessBaseAPI(psm=PSM.AUTO_OSD) as api:\n",
    "# #     image = Image.open(\"/usr/src/tesseract/testing/eurotext.tif\")\n",
    "#     api.SetImage(Image.fromarray(result, \"L\"))\n",
    "#     api.Recognize()\n",
    " \n",
    "#     it = api.AnalyseLayout() # 对目标页面进行分析\n",
    "#     orientation, direction, order, deskew_angle = it.Orientation() # 获取页面和文字方向\n",
    "#     print(\"Orientation: {:d}\".format(orientation))\n",
    "#     print(\"WritingDirection: {:d}\".format(direction))\n",
    "#     print(\"TextlineOrder: {:d}\".format(order))\n",
    "#     print(\"Deskew angle: {:.4f}\".format(deskew_angle))\n",
    "#     result = imutils.rotate(result, 0.8)\n",
    "#     Image.fromarray(result, \"L\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tesserocr import PyTessBaseAPI, PSM, RIL\n",
    "\n",
    "# SYMBOLS = '()[]{}+-*/<=>^、~.,?!%;:#\\'\\\"\\\\↑↓'\n",
    "# NUMBERS = '0123456789'\n",
    "# LETTERS = 'abcdefghigklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "# CHARBASE = '序号英文名称中文名称结果状态单位参考值项目结果参考值单位简称参考范围单位检测方法检验项目测定结果区间提示备注代码缩写代号'\n",
    "\n",
    "\n",
    "# image = Image.fromarray(result, \"L\")\n",
    "# image_2 = cv2.cvtColor(np.array(image), cv2.COLOR_GRAY2RGB)\n",
    "# with PyTessBaseAPI(lang='chi_sim') as api:\n",
    "#     api.SetImage(image)\n",
    "#     api.SetVariable('tessedit_char_whitelist',''.join(set('<=-～()+-abcdefghijklmnopqrstuvwxyz/\\\n",
    "#                 葡萄糖白细胞计数中性目百变异系标准差网织率总比↑\\\n",
    "#                 ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890.\\\n",
    "#                 %淋巴细胞单核嗜酸粒碱绝对值红蛋血压积平均量\\\n",
    "#                 浓度分布宽小板体性沉大肺炎支原反应' + SYMBOLS + NUMBERS + LETTERS + CHARBASE)))\n",
    "# #     api.SetVariable('preserve_interword_spaces','1')\n",
    "\n",
    "\n",
    "#     boxes = api.GetComponentImages(RIL.WORD, True) # 查找图像内图像块，并将分割后的图像块返回到boxes迭代器中\n",
    "#     print('Found {0} textline image components.'.format(len(boxes)))\n",
    "#     for i, (im, box, _, _) in enumerate(boxes):\n",
    "# #         display(im)\n",
    "# #         print(\"======================================\")\n",
    "        \n",
    "#         x, y, w, h = box['x'], box['y'], box['w'], box['h']\n",
    "#         cv2.rectangle(image_2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "# # #         print(x, y, w, h)\n",
    "# #         #im 是一个PIL图像对象\n",
    "# #         #box 是一个键包括x, y, w, h的词典\n",
    "# # #         api.SetRectangle(x, y, w, h)\n",
    "# # #         ocrResult = api.GetUTF8Text() # 输出指定区域内的UTF-8编码的文本\n",
    "# # #         conf = api.MeanTextConf() # 输出文本的确信度\n",
    "# #         block = np.array(image)[y:y+h+1, x:x+w + 1]\n",
    "# #         sub_image = Image.fromarray(block, \"L\")\n",
    "       \n",
    "# # #     for i_c, (img_c, box) in enumerate(components):\n",
    "# # #         display(img_c)\n",
    "# Image.fromarray(image_2, \"RGB\").show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from tesserocr import PyTessBaseAPI, PSM, RIL\n",
    "\n",
    "# SYMBOLS = '()[]{}+-*/<=>^、~.,?!%;:#\\'\\\"\\\\↑↓'\n",
    "# NUMBERS = '0123456789'\n",
    "# LETTERS = 'abcdefghigklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "# CHARBASE = '序号英文名称中文名称结果状态单位参考值项目结果参考值单位简称参考范围单位检测方法检验项目测定结果区间提示备注代码缩写代号'\n",
    "\n",
    "\n",
    "# image = Image.fromarray(result, \"L\")\n",
    "# with PyTessBaseAPI(lang='chi_sim') as api:\n",
    "#     api.SetImage(image)\n",
    "# #     components = api.GetConnectedComponents()\n",
    "# #     print(components)\n",
    "#     api.SetVariable('tessedit_char_whitelist',''.join(set('<=-～()+-abcdefghijklmnopqrstuvwxyz/\\\n",
    "#                 葡萄糖白细胞计数中性目百变异系标准差网织率总比↑\\\n",
    "#                 ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890.\\\n",
    "#                 %淋巴细胞单核嗜酸粒碱绝对值红蛋血压积平均量\\\n",
    "#                 浓度分布宽小板体性沉大肺炎支原反应' + SYMBOLS + NUMBERS + LETTERS + CHARBASE)))\n",
    "# #     api.SetVariable('preserve_interword_spaces','1')\n",
    "#     components = api.GetConnectedComponents()\n",
    "# #     print(components)\n",
    "# #     print(zip(*components))\n",
    "#     for i, (im, component) in enumerate(components):\n",
    "#         display(im)\n",
    "# #         print(\"---------------\")b\n",
    "\n",
    "\n",
    "# #     boxes = api.GetComponentImages(RIL.TEXTLINE, True) # 查找图像内图像块，并将分割后的图像块返回到boxes迭代器中\n",
    "# #     print('Found {0} textline image components.'.format(len(boxes)))\n",
    "# #     for i, (im, box, _, _) in enumerate(boxes):\n",
    "# # #         display(im)\n",
    "# # #         with PyTessBaseAPI(lang='chi_sim') as api_2:\n",
    "# # #             api_2.SetImage(im)\n",
    "# # #             api_2.SetVariable('preserve_interword_spaces','1')\n",
    "# # #             words = api_2.GetWords()\n",
    "# # #             print(words)\n",
    "# # # #             for i_2, (im_2, word) in enumerate(words):\n",
    "# # # #                 display(im_2)\n",
    "# # # #                 print(\"---------------\")\n",
    "# #         print(\"======================================\")\n",
    "        \n",
    "# #         x, y, w, h = box['x'], box['y'], box['w'], box['h']\n",
    "# # #         print(x, y, w, h)\n",
    "# #         #im 是一个PIL图像对象\n",
    "# #         #box 是一个键包括x, y, w, h的词典\n",
    "# # #         api.SetRectangle(x, y, w, h)\n",
    "# # #         ocrResult = api.GetUTF8Text() # 输出指定区域内的UTF-8编码的文本\n",
    "# # #         conf = api.MeanTextConf() # 输出文本的确信度\n",
    "# #         block = np.array(image)[y:y+h+1, x:x+w + 1]\n",
    "# #         sub_image = Image.fromarray(block, \"L\")\n",
    "        \n",
    "        \n",
    "# #         display(sub_image)\n",
    "# # #         with PyTessBaseAPI(lang='chi_sim') as api_2:\n",
    "# # #             api_2.SetImage(sub_image)\n",
    "# # # #             api_2.SetVariable('preserve_interword_spaces','1')\n",
    "# # #             block_boxes = api_2.GetComponentImages(RIL.WORD, True)\n",
    "# # #             print('    Found {0} word image components within block.'.format(len(block_boxes)))\n",
    "# # #             for block_i, (block_im, block_box, _, _) in enumerate(block_boxes):\n",
    "# # #                 block_x, block_y, block_w, block_h = block_box['x'], block_box['y'], block_box['w'], block_box['h']\n",
    "# # #         #         print(x, y, w, h)\n",
    "# # #                 #im 是一个PIL图像对象\n",
    "# # #                 #box 是一个键包括x, y, w, h的词典\n",
    "# # #         #         api.SetRectangle(block_x, block_y, block_w, block_h)\n",
    "# # #         #         ocrResult = api.GetUTF8Text() # 输出指定区域内的UTF-8编码的文本\n",
    "# # #         #         conf = api.MeanTextConf() # 输出文本的确信度\n",
    "# # #                 block_word = block[block_y:block_y+block_h+1, block_x:block_x+block_w + 1]\n",
    "# # #                 sub_image_word = Image.fromarray(block_word, \"L\")\n",
    "# # #                 display(sub_image_word)\n",
    "        \n",
    "# # #         print(\"------------------------------\")\n",
    "# # #     for i_c, (img_c, box) in enumerate(components):\n",
    "# # #         display(img_c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save image in set directory \n",
    "# # Read RGB image \n",
    "# p = \"../Jerry.in\"\n",
    "\n",
    "# matrices = []\n",
    "# for r,d,f in os.walk(p):\n",
    "#     for file_name in f:\n",
    "#         if (not file_name.endswith(\".jpeg\") and not file_name.endswith(\".jpg\") and not file_name.endswith(\".png\")):\n",
    "#             continue\n",
    "#         print(p + \"/\" + file_name)\n",
    "#         scr_path = p + \"/\" + file_name\n",
    "#         postfix = file_name.split(\".\")[-1]\n",
    "#         main_name = \".\".join(file_name.split(\".\")[:-1])\n",
    "#         dst_path = '../Jerry.out/' + main_name + \".out.png\"\n",
    "#         rt = ImageProcessor().process_image(scr_path, dst_path, dpi = 70)\n",
    "#         Image.fromarray(rt).show()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
